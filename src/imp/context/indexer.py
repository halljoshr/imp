"""Indexer — Generate .index.md files and cache project scans.

L1 constraint: Only import from imp.context.models, pathlib, datetime, stdlib.
"""

from datetime import datetime
from pathlib import Path

from imp.context.models import DirectoryModule, ProjectScan


def render_root_index(scan: ProjectScan) -> str:
    """Render root .index.md markdown content.

    Args:
        scan: Complete project scan

    Returns:
        Markdown string for root .index.md
    """
    lines = [
        "# Project Index",
        "",
        f"Generated by `imp init` on {scan.scanned_at.strftime('%Y-%m-%d')}.",
        "",
    ]

    # Modules table
    lines.append("## Modules")
    if scan.modules:
        lines.append("| Module | Purpose | Files | Functions | Classes |")
        lines.append("|--------|---------|-------|-----------|---------|")
        for module in scan.modules:
            purpose = module.purpose or "—"
            num_files = len(module.files)
            num_functions = sum(len(f.functions) for f in module.files)
            num_classes = sum(len(f.classes) for f in module.files)
            lines.append(
                f"| {module.path} | {purpose} | {num_files} | {num_functions} | {num_classes} |"
            )
    else:
        lines.append("*(No modules found)*")
    lines.append("")

    # File types summary
    lines.append("## File Types")
    language_stats: dict[str, tuple[int, int]] = {}  # language -> (file_count, line_count)
    for module in scan.modules:
        for file in module.files:
            lang = file.file_info.language.value
            count, total_lines = language_stats.get(lang, (0, 0))
            language_stats[lang] = (count + 1, total_lines + file.file_info.line_count)

    if language_stats:
        for lang, (count, total_lines) in sorted(language_stats.items()):
            lang_name = lang.capitalize()
            lines.append(f"- {lang_name}: {count} files ({total_lines:,} lines)")
    else:
        lines.append("- Python: 0 files (0 lines)")
    lines.append("")

    # Key exports
    has_exports = any(f.exports for m in scan.modules for f in m.files)
    if has_exports:
        lines.append("## Key Exports")
        for module in scan.modules:
            for file in module.files:
                if file.exports:
                    file_path = f"{module.path}{file.file_info.path}"
                    exports_str = ", ".join(file.exports)
                    lines.append(f"- `{file_path}`: {exports_str}")
        lines.append("")

    return "\n".join(lines)


def render_module_index(module: DirectoryModule) -> str:
    """Render per-module .index.md markdown content.

    Args:
        module: Directory module to render

    Returns:
        Markdown string for module .index.md
    """
    lines = [
        f"# {module.path} — Module Index",
        "",
    ]

    # Exports section
    exports = [(file.file_info.path, export) for file in module.files for export in file.exports]
    if exports:
        lines.append("## Exports")
        # Group by file or just list all
        for _file_path, export_name in exports:
            lines.append(f"- `{export_name}`")
        lines.append("")

    # Files section
    lines.append(f"## Files ({len(module.files)})")
    if module.files:
        for file in module.files:
            file_path = file.file_info.path
            line_count = file.file_info.line_count

            # Build description
            description_parts = []
            if file.module_docstring:
                description_parts.append(file.module_docstring)
            else:
                # Show first class or function name
                if file.classes:
                    description_parts.append(file.classes[0].name)
                elif file.functions:
                    description_parts.append(file.functions[0].name)

            desc_str = " — " + ", ".join(description_parts) if description_parts else ""
            lines.append(f"- `{file_path}`{desc_str} ({line_count} lines)")
    lines.append("")

    # Dependencies section
    all_imports = [imp for file in module.files for imp in file.imports]
    if all_imports:
        external = sorted({imp.module for imp in all_imports if not imp.module.startswith("imp.")})
        internal = sorted({imp.module for imp in all_imports if imp.module.startswith("imp.")})

        lines.append("## Dependencies")
        if external:
            lines.append(f"- External: {', '.join(external)}")
        if internal:
            lines.append(f"- Internal: {', '.join(internal)}")
        lines.append("")

    # Last updated
    now = datetime.now()
    lines.append("## Last Updated")
    lines.append(f"{now.strftime('%Y-%m-%d')} by imp init")
    lines.append("")

    return "\n".join(lines)


def generate_indexes(scan: ProjectScan, project_root: Path) -> list[Path]:
    """Write all .index.md files.

    Args:
        scan: Complete project scan
        project_root: Root directory of the project

    Returns:
        List of paths to written .index.md files
    """
    written_paths: list[Path] = []

    # Write root index
    root_index_path = project_root / ".index.md"
    root_content = render_root_index(scan)
    root_index_path.write_text(root_content)
    written_paths.append(root_index_path)

    # Write per-module indexes
    for module in scan.modules:
        module_dir = project_root / module.path
        module_dir.mkdir(parents=True, exist_ok=True)

        module_index_path = module_dir / ".index.md"
        module_content = render_module_index(module)
        module_index_path.write_text(module_content)
        written_paths.append(module_index_path)

    return written_paths


def save_cache(scan: ProjectScan, project_root: Path) -> Path:
    """Save ProjectScan to .imp/scan.json.

    Creates .imp directory if it doesn't exist.
    Creates .imp/.gitignore with '*' to ignore all cache files.

    Args:
        scan: Project scan to serialize
        project_root: Root directory of the project

    Returns:
        Path to the written scan.json file
    """
    imp_dir = project_root / ".imp"
    imp_dir.mkdir(exist_ok=True)

    # Create .gitignore
    gitignore_path = imp_dir / ".gitignore"
    gitignore_path.write_text("*\n")

    # Serialize scan to JSON
    scan_path = imp_dir / "scan.json"
    json_content = scan.model_dump_json(indent=2)
    scan_path.write_text(json_content)

    return scan_path
